# /// script
# requires-python = ">=3.10"
# dependencies = [
#     "openai",
# ]
# ///

import os
import json
import sys
import time
from openai import OpenAI

# ==========================================
# é…ç½®åŒºåŸŸ
# ==========================================
API_KEY = os.getenv("DASHSCOPE_API_KEY")  # æ”¹ä¸ºé˜¿é‡Œäº‘
BASE_URL = os.getenv("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
MODEL_NAME = os.getenv("DASHSCOPE_MODEL_NAME", "qwen-plus")

if not API_KEY:
    print("âŒ Error: è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY")
    sys.exit(1)

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

class LongArticleAgent:
    def __init__(self, topic):
        self.topic = topic
        self.outline = []
        self.articles = []

    def step1_generate_outline(self):
        """Step 1: ç”Ÿæˆç« èŠ‚å¤§çº²"""
        print(f"ğŸ“‹ æ­£åœ¨è§„åˆ’ä¸»é¢˜: {self.topic}...")
        
        # æ”¹è¿›çš„ Prompt
        prompt = f"""
        è¯·ä¸ºä¸»é¢˜ã€Š{self.topic}ã€‹ç”Ÿæˆä¸€ä¸ªåŒ…å«3ä¸ªç« èŠ‚çš„å¤§çº²ã€‚
        æ¯ä¸ªç« èŠ‚çš„æ ‡é¢˜åº”ç®€æ´æ˜äº†ï¼Œèƒ½å¤Ÿæ¦‚æ‹¬è¯¥éƒ¨åˆ†çš„æ ¸å¿ƒå†…å®¹ã€‚
        è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ä¸¥æ ¼çš„JSONæ•°ç»„ï¼Œä¾‹å¦‚ï¼š
        ["ç¬¬ä¸€ç« ï¼šå¼•è¨€", "ç¬¬äºŒç« ï¼šæŠ€æœ¯åŸç†", "ç¬¬ä¸‰ç« ï¼šæœªæ¥å±•æœ›"]
        ä¸è¦åŒ…å«ä»»ä½•å…¶ä»–è§£é‡Šæˆ–æ–‡æœ¬ã€‚
        """
        
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œè§„åˆ’å¸ˆï¼Œåªè¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–å†…å®¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.7
            )
            content = response.choices[0].message.content
            
            # æ¸…ç†å¯èƒ½çš„ Markdown ä»£ç å—ï¼ˆå¦‚ ```json ... ```ï¼‰
            content = content.strip()
            if content.startswith("```"):
                # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ ```
                lines = content.splitlines()
                if lines[0].startswith("```"):
                    lines = lines[1:]
                if lines and lines[-1].startswith("```"):
                    lines = lines[:-1]
                content = "\n".join(lines).strip()
            
            # è§£æ JSON
            data = json.loads(content)
            
            # å¤„ç†è¿”å›çš„æ•°æ®ï¼šå¯èƒ½ç›´æ¥æ˜¯åˆ—è¡¨ï¼Œä¹Ÿå¯èƒ½æ˜¯åŒ…å«åˆ—è¡¨çš„å­—å…¸
            if isinstance(data, list):
                self.outline = data
            elif isinstance(data, dict):
                # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ªåˆ—è¡¨å€¼
                for value in data.values():
                    if isinstance(value, list):
                        self.outline = value
                        break
                else:
                    raise ValueError("è¿”å›çš„JSONä¸­æœªæ‰¾åˆ°åˆ—è¡¨")
            else:
                raise ValueError("è¿”å›çš„æ•°æ®æ ¼å¼å¼‚å¸¸")
            
            if not self.outline:
                raise ValueError("å¤§çº²åˆ—è¡¨ä¸ºç©º")

            print(f"âœ… å¤§çº²å·²ç”Ÿæˆ: {self.outline}")

        except Exception as e:
            print(f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥: {e}")
            print(f"Raw Content: {content if 'content' in locals() else 'None'}")
            sys.exit(1)

    def step2_generate_content_loop(self):
        """Step 2: å¾ªç¯ç”Ÿæˆå†…å®¹ï¼Œå¹¶ç»´æŠ¤ Context"""
        if not self.outline:
            return

        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡æ‘˜è¦
        previous_summary = "æ–‡ç« å¼€å§‹ã€‚"
    
        print("\nğŸš€ å¼€å§‹æ’°å†™æ­£æ–‡...")
        for i, chapter in enumerate(self.outline):
            print(f"[{i+1}/{len(self.outline)}] æ­£åœ¨æ’°å†™: {chapter}...")
        
        # æ„é€  Promptï¼Œæ ¸å¿ƒåœ¨äº Context çš„æ³¨å…¥
            prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šä½œå®¶ã€‚è¯·æ’°å†™ç« èŠ‚ï¼š"{chapter}"ã€‚

        ã€å‰æƒ…æè¦ã€‘ï¼š
        {previous_summary}

        è¦æ±‚ï¼š
        1. å†…å®¹å……å®ï¼Œå­—æ•°çº¦ 300 å­—ã€‚
        2. å¿…é¡»æ‰¿æ¥ã€å‰æƒ…æè¦ã€‘çš„é€»è¾‘ï¼Œä¸è¦é‡å¤å‰æ–‡å†…å®¹ã€‚
        3. è¯­è¨€æµç•…ï¼Œé€»è¾‘æ¸…æ™°ã€‚
        """
            
            try:
                response = client.chat.completions.create(
                    model=MODEL_NAME,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7,
                    max_tokens=800  # æ§åˆ¶è¾“å‡ºé•¿åº¦ï¼Œé¿å…è¿‡é•¿
                )
                content = response.choices[0].message.content
                self.articles.append(f"## {chapter}\n\n{content}")
                
                # æ›´æ–° Contextï¼šæˆªå–æœ€å 200 å­—ä½œä¸ºä¸‹ä¸€ç« çš„å‰æƒ…æè¦
                # æ›´é«˜çº§çš„æ–¹æ³•ï¼šè®©æ¨¡å‹å¯¹æœ¬ç« ç”Ÿæˆä¸€ä¸ªæ‘˜è¦ï¼Œä½†ç®€å•æˆªå–ä¹Ÿå¯ä»¥
                previous_summary = content[-200:]  # å–æœ€å200å­—ç¬¦ï¼Œæ³¨æ„æ˜¯ä¸­æ–‡å­—ç¬¦
                
            except Exception as e:
                print(f"âš ï¸ ç« èŠ‚ {chapter} ç”Ÿæˆå¤±è´¥: {e}")
                # å¦‚æœå¤±è´¥ï¼Œå¯ä»¥é€‰æ‹©è·³è¿‡æˆ–ä½¿ç”¨å¤‡é€‰æ‘˜è¦
                continue

    def save_result(self):
        if not self.articles:
            print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•å†…å®¹")
            return
            
        filename = "final_article.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(f"# {self.topic}\n\n")
            f.write("\n\n".join(self.articles))
        print(f"\nğŸ‰ æ–‡ç« å·²ä¿å­˜è‡³ {filename}")

if __name__ == "__main__":
    print(f"ğŸ”Œ Endpoint: {BASE_URL}")
    print(f"ğŸ§  Model: {MODEL_NAME}\n")
    
    agent = LongArticleAgent("2025å¹´ DeepSeek å¯¹ AI è¡Œä¸šçš„å½±å“")
    agent.step1_generate_outline()
    agent.step2_generate_content_loop()
    agent.save_result()